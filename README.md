# ğŸ† ETL Pipeline - DonnÃ©es de la Coupe du Monde FIFA

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code Coverage](https://img.shields.io/badge/coverage-85%25-brightgreen.svg)](test/)

## ğŸ“‹ Description

Ce projet implÃ©mente un pipeline ETL (Extract, Transform, Load) complet pour consolider et analyser les donnÃ©es historiques des matchs de la Coupe du Monde FIFA de 1930 Ã  2022. Le systÃ¨me extrait les donnÃ©es de multiples sources (CSV et JSON), les transforme pour assurer leur cohÃ©rence, et les charge dans une base de donnÃ©es PostgreSQL.

### ğŸ¯ Objectifs du projet

- **Centraliser** les donnÃ©es de plusieurs Ã©ditions de la Coupe du Monde (1930-2010, 2014, 2018, 2022)
- **Normaliser** les formats de donnÃ©es hÃ©tÃ©rogÃ¨nes provenant de diffÃ©rentes sources
- **Harmoniser** les informations (noms d'Ã©quipes, stades, rÃ©sultats)
- **Stocker** les donnÃ©es dans une base PostgreSQL pour faciliter l'analyse
- **Garantir** la qualitÃ© des donnÃ©es avec une suite de tests


## ğŸ› ï¸ Technologies utilisÃ©es

### Langages et frameworks

- **Python 3.10+** - Langage principal
- **pandas** - Manipulation de donnÃ©es
- **SQLAlchemy** - ORM et connexion base de donnÃ©es
- **psycopg2** - Driver PostgreSQL
- **pytest** - Framework de tests

### Outils de dÃ©veloppement

- **Jupyter** - Notebooks d'analyse
- **pytest-cov** - Couverture de code
- **python-dotenv** - Gestion des variables d'environnement
- **PyYAML** - Parsing de configuration

### Base de donnÃ©es

- **PostgreSQL** - SystÃ¨me de gestion de base de donnÃ©es relationnelle
## ğŸ”„ Architecture globale

![architecture ETL](Sans-titre-2025-04-04-1326.png)

### 1. **Extract** - Extraction des donnÃ©es


Le module `extract.py` gÃ¨re l'extraction depuis diffÃ©rentes sources :

- **CSV** : Lecture automatique avec dÃ©tection du dÃ©limiteur (`,`, `;`, `|`, `\t`)
- **JSON** : Parsing de structures imbriquÃ©es (Ã©quipes, stades, groupes, matchs)

```python
# Extraction automatique avec gestion des sÃ©parateurs
df = fct_read_csv(file_path)

# Lecture de JSON complexe
dfs = fct_read_json_nested(json_path)
```

### 2. **Transform** - Transformation et nettoyage

Le module `transform.py` normalise les donnÃ©es :

- Standardisation des noms de colonnes
- Conversion des formats de dates
- Harmonisation des noms d'Ã©quipes et de stades
- Mapping des phases du tournoi (groupes, huitiÃ¨mes, quarts, etc.)
- Gestion des valeurs manquantes
- Validation des types de donnÃ©es

```python
# Transformation par Ã©dition
df_2010_clean = fct_transform_2010(df_2010, config)
df_2014_clean = trf_file_wcup_2014(df_2014, config)
df_2018_clean = fct_transform_data_2018(dfs_2018, config)
df_2022_clean = transform_2022_data(df_2022, config)
```

### 3. **Load** - Chargement en base

Le module `load.py` gÃ¨re l'insertion dans PostgreSQL :

- CrÃ©ation automatique du schÃ©ma de table
- Insertion avec gestion des transactions
- Support de l'upsert (insert/update)

```python
# CrÃ©ation du moteur SQLAlchemy
engine = create_postgres_engine(host, database, user, password)

# Chargement des donnÃ©es
df_final.to_sql("matches", engine, if_exists="replace")
```

## ğŸ“Š SchÃ©ma de la base de donnÃ©es

### Table `matches`

| Colonne       | Type         | Description                           |
|---------------|--------------|---------------------------------------|
| `match_id`    | INTEGER (PK) | Identifiant unique du match           |
| `date`        | DATE         | Date du match                         |
| `home_team`   | VARCHAR(100) | Ã‰quipe Ã  domicile                     |
| `away_team`   | VARCHAR(100) | Ã‰quipe Ã  l'extÃ©rieur                  |
| `home_result` | INTEGER      | Score de l'Ã©quipe Ã  domicile          |
| `away_result` | INTEGER      | Score de l'Ã©quipe Ã  l'extÃ©rieur       |
| `stage`       | VARCHAR(50)  | Phase du tournoi                      |
| `edition`     | INTEGER      | AnnÃ©e de l'Ã©dition                    |
| `city`        | VARCHAR(100) | Ville oÃ¹ s'est jouÃ© le match          |


## ğŸ—ï¸ Architecture du projet

```
Brief-2-ETL-de-donnees-footballistiques-Wickets-Sprinters/
â”‚
â”œâ”€â”€ config.yaml                 # Configuration du pipeline ETL
â”œâ”€â”€ main.py                     # Point d'entrÃ©e principal
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ pytest.ini                  # Configuration des tests
â”œâ”€â”€ .env                        # Variables d'environnement (non versionnÃ©)
â”‚
â”œâ”€â”€ data/                       # DonnÃ©es sources
â”‚   â”œâ”€â”€ matches_19302010.csv    # Matchs 1930-2010
â”‚   â”œâ”€â”€ WorldCupMatches2014.csv # Matchs 2014
â”‚   â”œâ”€â”€ data_2018.json          # DonnÃ©es 2018 (format JSON)
â”‚   â””â”€â”€ Fifa_world_cup_matches.csv # Matchs 2022
â”‚
â”œâ”€â”€ src/                        # Code source
â”‚   â””â”€â”€ etl/                    # Modules ETL
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ extract.py          # Extraction des donnÃ©es
â”‚       â”œâ”€â”€ transform.py        # Transformation et nettoyage
â”‚       â”œâ”€â”€ load.py             # Chargement en base de donnÃ©es
â”‚       â””â”€â”€ utils.py            # Fonctions utilitaires
â”‚
â”œâ”€â”€ test/                       # Tests unitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_extract.py
â”‚   â”œâ”€â”€ test_transform.py
â”‚   â”œâ”€â”€ test_load.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ notebook/                   # Notebooks d'analyse exploratoire
â”‚   â”œâ”€â”€ notebook_19302010.ipynb
â”‚   â”œâ”€â”€ notebook_2014.ipynb
â”‚   â”œâ”€â”€ notebook_2018_extract.ipynb
â”‚   â”œâ”€â”€ notebook_2018_transform.ipynb
â”‚   â””â”€â”€ notebook_2022.ipynb
â”‚
â””â”€â”€ src/eda/                    # Analyses exploratoires (EDA)
    â””â”€â”€ eda_*.ipynb             # Notebooks EDA par membre d'Ã©quipe
```
## ğŸš€ Installation

### PrÃ©requis

- Python 3.10 ou supÃ©rieur
- PostgreSQL 12 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Ã‰tapes d'installation

1. **Cloner le dÃ©pÃ´t**

```bash
git clone https://github.com/Simplon-DE-P1-2025/Brief-2-ETL-de-donnees-footballistiques-Wickets-Sprinters.git
cd Brief-2-ETL-de-donnees-footballistiques-Wickets-Sprinters
```

2. **CrÃ©er un environnement virtuel**

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
```

3. **Installer les dÃ©pendances**

```bash
pip install -r requirements.txt
```

4. **Configurer les variables d'environnement**

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```env
DB_HOST=localhost
DB_DATABASE=worldcup_db
DB_USER=votre_utilisateur
DB_PASSWORD=votre_mot_de_passe
```

5. **CrÃ©er la base de donnÃ©es PostgreSQL**

```bash
# Connexion Ã  PostgreSQL
psql -U postgres

# CrÃ©ation de la base de donnÃ©es
CREATE DATABASE worldcup_db;
```

## ğŸ’» Utilisation

### ExÃ©cution du pipeline complet

```bash
python main.py
```

Le pipeline va :
1. âœ… Extraire les donnÃ©es des fichiers sources
2. âœ… Transformer et nettoyer les donnÃ©es
3. âœ… Fusionner les datasets de toutes les Ã©ditions
4. âœ… GÃ©nÃ©rer les identifiants uniques
5. âœ… Charger les donnÃ©es dans PostgreSQL

### Utilisation des modules individuels

```python
from src.etl.extract import fct_read_csv, fct_read_json_nested
from src.etl.transform import fct_transform_2010
from src.etl.load import create_postgres_engine

# Extraction
df = fct_read_csv("data/matches_19302010.csv")

# Transformation
df_clean = fct_transform_2010(df, config)

# Connexion Ã  la base
engine = create_postgres_engine(host, database, user, password)
```

## ğŸ§ª Tests

Le projet dispose d'une suite de tests complÃ¨te avec une couverture de code de **85%**.

### ExÃ©cuter tous les tests

```bash
pytest
```

### Tests avec rapport de couverture

```bash
pytest --cov=./src --cov-report=term-missing
```

### Tests par module

```bash
# Test d'extraction
pytest test/test_extract.py

# Test de transformation
pytest test/test_transform.py

# Test de chargement
pytest test/test_load.py

# Test des utilitaires
pytest test/test_utils.py
```

### ExÃ©cuter des tests spÃ©cifiques

```bash
# Test d'une fonction prÃ©cise
pytest test/test_extract.py::test_fct_read_csv -v

# Tests en mode verbose
pytest -v

# ArrÃªt au premier Ã©chec
pytest -x
```

## âš™ï¸ Configuration

Le fichier `config.yaml` centralise la configuration du pipeline :

### Structure de configuration

```yaml
# Chemins des fichiers sources
root_csv_2010: "data/matches_19302010.csv"
root_csv_2014: "data/WorldCupMatches2014.csv"
root_csv_2022: "data/Fifa_world_cup_matches.csv"
root_json_2018: "data/data_2018.json"

# Mapping des colonnes pour 2010
dict_columns_2010:
  year: date
  team1: home_team
  team2: away_team
  venue: city
  round: stage

# Normalisation des phases du tournoi
stage_mapping_2010:
  GROUP_STAGE: group_stage
  1/2_FINAL: semi_finals
  FINAL: final
  # ... autres mappings

# Colonnes Ã  conserver
columns_to_keep_2010:
  - date
  - home_team
  - away_team
  - home_result
  - away_result
  - stage
```

## ğŸ“ˆ Analyses exploratoires (EDA)

Le dossier `notebook/` et `src/eda/` contiennent des analyses dÃ©taillÃ©es.


### Notebooks disponibles

| Notebook | Description |
|----------|-------------|
| `notebook_19302010.ipynb` | Analyse des donnÃ©es 1930-2010 |
| `notebook_2014.ipynb` | Analyse Coupe du Monde 2014 |
| `notebook_2018_extract.ipynb` | Extraction donnÃ©es 2018 |
| `notebook_2018_transform.ipynb` | Transformation donnÃ©es 2018 |
| `notebook_2022.ipynb` | Analyse Coupe du Monde 2022 |


## ğŸ‘¥ Ã‰quipe

### Wickets Sprinters : **Kaouter** | **Ashley** | **Ahmed**  |Â **Alexandre** 

## ğŸ“ Licence

Ce projet est dÃ©veloppÃ© dans le cadre d'une formation Ã  Simplon.


---

<div align="center">
  <strong>âš½ DÃ©veloppÃ© avec passion pour le football et les donnÃ©es âš½</strong>
  <br>
  <sub>Projet Simplon - Data Engineering - 2025</sub>
</div>
